# Guide d'Utilisation - Mod√®les Personnalis√©s

## üéØ Vue d'Ensemble

Votre syst√®me de classification d'exoplan√®tes permet maintenant d'entra√Æner des mod√®les personnalis√©s et de les utiliser imm√©diatement pour faire des pr√©dictions. Voici comment proc√©der :

## üìã Processus Complet

### 1Ô∏è‚É£ **Entra√Æner un Mod√®le Personnalis√©**

1. **Aller dans l'onglet "Hyperparam√®tres"**
2. **S√©lectionner un type de mod√®le** (RandomForest, XGBoost, SVM, KNN, R√©gression Logistique)
3. **Ajuster les hyperparam√®tres** selon vos besoins :
   - Utilisez les sliders pour les param√®tres num√©riques
   - S√©lectionnez les options dans les listes d√©roulantes
   - Activez/d√©sactivez les switches selon les besoins

4. **Cliquer sur "Entra√Æner le Mod√®le"**
   - Une barre de progression s'affiche avec les √©tapes d'entra√Ænement
   - Le temps estim√© restant (ETA) est affich√©
   - 7 √©tapes sont simul√©es : chargement ‚Üí pr√©paration ‚Üí division ‚Üí entra√Ænement ‚Üí validation ‚Üí m√©triques ‚Üí finalisation

5. **Consulter les r√©sultats** :
   - M√©triques compl√®tes (Accuracy, F1-Macro, ROC-AUC, AUC Score)
   - Matrice de confusion d√©taill√©e
   - Temps d'entra√Ænement

### 2Ô∏è‚É£ **Utiliser le Mod√®le pour des Pr√©dictions**

1. **Aller dans l'onglet "Pr√©dire"**
2. **Le mod√®le personnalis√© appara√Æt automatiquement** dans la liste des mod√®les disponibles
3. **Identifier les mod√®les personnalis√©s** :
   - Badge "Personnalis√©" violet
   - Nom du type + "Personnalis√©" + ID court
   - F1-Score affich√©

4. **S√©lectionner votre mod√®le personnalis√©**
5. **Saisir les caract√©ristiques** de l'exoplan√®te
6. **Cliquer sur "Classify Exoplanet"**
7. **Voir le r√©sultat** avec la classe pr√©dite et le niveau de confiance

### 3Ô∏è‚É£ **G√©rer Vos Mod√®les**

Dans l'onglet "Hyperparam√®tres", section "Mod√®les Personnalis√©s Entra√Æn√©s" :

- **Voir l'historique** de tous vos mod√®les entra√Æn√©s
- **Supprimer des mod√®les** avec le bouton üóëÔ∏è
- **Revenir aux mod√®les par d√©faut** avec le bouton "Mod√®les Par D√©faut"

## üîÑ Workflow Typique

```
1. Hyperparam√®tres ‚Üí Configurer ‚Üí Entra√Æner
                         ‚Üì
2. Pr√©dire ‚Üí S√©lectionner mod√®le personnalis√© ‚Üí Pr√©dire
                         ‚Üì
3. R√©sultats ‚Üí Voir historique des pr√©dictions
```

## üìä Types de Mod√®les Disponibles

### **Random Forest**
- `n_estimators` : Nombre d'arbres (50-500)
- `max_depth` : Profondeur maximale (5-20 ou None)
- `min_samples_split` : √âchantillons minimum pour diviser (2-10)
- `min_samples_leaf` : √âchantillons minimum par feuille (1-4)
- `max_features` : Caract√©ristiques maximum ('sqrt', 'log2', None)

### **XGBoost**
- `n_estimators` : Nombre d'estimateurs (50-200)
- `max_depth` : Profondeur maximale (3-10)
- `learning_rate` : Taux d'apprentissage (0.01-0.2)
- `subsample` : Sous-√©chantillonnage (0.8-1.0)
- `colsample_bytree` : √âchantillonnage des colonnes (0.8-1.0)

### **SVM**
- `C` : Param√®tre de r√©gularisation (0.1-100)
- `kernel` : Type de noyau ('rbf', 'poly', 'linear')
- `gamma` : Coefficient du noyau ('scale', 'auto')
- `degree` : Degr√© du polyn√¥me (2-4)

### **KNN**
- `n_neighbors` : Nombre de voisins (3-20)
- `weights` : Pond√©ration ('uniform', 'distance')
- `metric` : M√©trique de distance ('euclidean', 'manhattan', 'minkowski')
- `p` : Param√®tre pour Minkowski (1-3)

### **R√©gression Logistique**
- `C` : Inverse de la r√©gularisation (0.1-100)
- `penalty` : Type de r√©gularisation ('l1', 'l2', 'elasticnet')
- `solver` : Algorithme d'optimisation ('liblinear', 'saga')
- `max_iter` : It√©rations maximum (1000-5000)

## üí° Conseils d'Optimisation

### **Pour Am√©liorer la Performance :**

1. **Random Forest** :
   - Augmentez `n_estimators` pour plus de stabilit√©
   - Ajustez `max_depth` pour √©viter le surapprentissage
   - Utilisez `max_features='sqrt'` pour de meilleures performances

2. **XGBoost** :
   - Diminuez `learning_rate` et augmentez `n_estimators`
   - Ajustez `max_depth` entre 3-7 pour √©quilibrer biais/variance
   - Utilisez `subsample` < 1.0 pour r√©duire le surapprentissage

3. **SVM** :
   - Commencez avec `C=1` et `kernel='rbf'`
   - Ajustez `C` pour contr√¥ler le surapprentissage
   - Testez diff√©rents noyaux selon vos donn√©es

4. **KNN** :
   - Testez diff√©rentes valeurs de `n_neighbors` (impaires)
   - Utilisez `weights='distance'` pour pond√©rer par distance
   - Choisissez la bonne m√©trique selon vos donn√©es

5. **R√©gression Logistique** :
   - Utilisez `penalty='l1'` pour s√©lection de caract√©ristiques
   - Augmentez `C` si le mod√®le sous-apprend
   - Diminuez `C` si le mod√®le sur-apprend

## üéØ M√©triques √† Surveiller

### **F1-Macro Score** (Principal)
- Moyenne non pond√©r√©e des F1-scores par classe
- Id√©al pour datasets d√©s√©quilibr√©s
- **Objectif : > 85%**

### **ROC-AUC**
- Capacit√© discriminante du mod√®le
- Insensible au d√©s√©quilibre des classes
- **Objectif : > 95%**

### **AUC Score**
- Sensible aux classes minoritaires
- Compl√©ment important au ROC-AUC
- **Objectif : > 95%**

## üöÄ Exemples de Configurations Optimales

### **Pour Haute Pr√©cision :**
```
XGBoost:
- n_estimators: 200
- max_depth: 7
- learning_rate: 0.05
- subsample: 0.8
- colsample_bytree: 0.8
```

### **Pour Rapidit√© :**
```
Random Forest:
- n_estimators: 100
- max_depth: 10
- min_samples_split: 5
- max_features: 'sqrt'
```

### **Pour Robustesse :**
```
SVM:
- C: 10
- kernel: 'rbf'
- gamma: 'scale'
```

## üîß D√©pannage

### **Si le F1-Score est faible :**
- Ajustez les hyperparam√®tres de r√©gularisation
- Testez un autre type de mod√®le
- V√©rifiez les donn√©es d'entr√©e

### **Si l'entra√Ænement est lent :**
- Diminuez `n_estimators` ou `max_depth`
- Utilisez des mod√®les plus simples (KNN, R√©gression Logistique)

### **Si le mod√®le sur-apprend :**
- Augmentez la r√©gularisation (diminuez `C`, ajoutez `penalty`)
- Diminuez la complexit√© du mod√®le
- Utilisez `subsample` < 1.0 pour XGBoost

## üìà Surveillance des Performances

1. **Comparez avec les mod√®les par d√©faut**
2. **Testez sur diff√©rents datasets**
3. **Surveillez la coh√©rence des pr√©dictions**
4. **Utilisez l'historique pour identifier les tendances**

---

Le syst√®me est maintenant compl√®tement int√©gr√© : **entra√Ænez ‚Üí utilisez ‚Üí g√©rez** vos mod√®les personnalis√©s en toute simplicit√© ! üéâ
